{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"align: center;\"><img src=\"https://static.tildacdn.com/tild6636-3531-4239-b465-376364646465/Deep_Learning_School.png\" width=\"400\"></p>\n",
        "\n",
        "# Глубокое обучение. Часть 2\n",
        "# Домашнее задание по теме \"Механизм внимания\""
      ],
      "metadata": {
        "id": "Ji8KtYOVGs8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Это домашнее задание проходит в формате peer-review. Это означает, что его будут проверять ваши однокурсники. Поэтому пишите разборчивый код, добавляйте комментарии и пишите выводы после проделанной работы.\n",
        "\n",
        "В этом задании вы будете решать задачу классификации математических задач по темам (многоклассовая классификация) с помощью Transformer.\n",
        "\n",
        "В качестве датасета возьмем датасет математических задач по разным темам. Нам необходим следующий файл:\n",
        "\n",
        "[Файл с классами](https://docs.google.com/spreadsheets/d/13YIbphbWc62sfa-bCh8MLQWKizaXbQK9/edit?usp=drive_link&ouid=104379615679964018037&rtpof=true&sd=true)"
      ],
      "metadata": {
        "id": "UAr-M8_1GJ6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hint:** не перезаписывайте модели, которые вы получите на каждом из этапов этого дз. Они ещё понадобятся."
      ],
      "metadata": {
        "id": "1fybMcmV0YRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 1 (2 балла)\n",
        "\n",
        "Напишите кастомный класс для модели трансформера для задачи классификации, использующей в качествке backbone какую-то из моделей huggingface.\n",
        "\n",
        "Т.е. конструктор класса должен принимать на вход название модели и подгружать её из huggingface, а затем использовать в качестве backbone (достаточно возможности использовать в качестве backbone те модели, которые упомянуты в последующих пунктах)"
      ],
      "metadata": {
        "id": "t395freCxpOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### This is just an interface example. You may change it if you want.\n",
        "\n",
        "class TransformerClassificationModel(nn.Module):\n",
        "    def __init__(base_transformer_model: Union[str, nn.Module]):\n",
        "        self.backbone = #...\n",
        "        # YOUR CODE: create additional layers for classfication\n",
        "\n",
        "    def forward(inputs, ...):\n",
        "        # YOUR CODE: propagate inputs through the model. Return dict with logits\n",
        "\n",
        "        outputs = {<YOUR CODE>}\n",
        "        return # YOUR CODE"
      ],
      "metadata": {
        "id": "eX4VGWquyiMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 2 (1 балл)\n",
        "\n",
        "Напишите функцию заморозки backbone у модели (если необходимо, возвращайте из функции модель)"
      ],
      "metadata": {
        "id": "Vd3kxX6hy0d4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze_backbone_function(model: TransformerClassificationModel):\n",
        "    pass"
      ],
      "metadata": {
        "id": "U8IuDosbzKe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 3 (2 балла)\n",
        "\n",
        "Напишите функцию, которая будет использована для тренировки (дообучения) трансформера (TransformerClassificationModel). Функция должна поддерживать обучение с замороженным и размороженным backbone."
      ],
      "metadata": {
        "id": "kybkw6MSzd-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "def train_transformer(transformer_model, freeze_backbone=True)\n",
        "    model = copy.copy(transformer_model)\n",
        "    ### YOUR CODE IS HERE\n",
        "\n",
        "    return finetuned_model"
      ],
      "metadata": {
        "id": "EDhrD0BHzxi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 4 (1 балл)\n",
        "\n",
        "Проверьте вашу функцию из предыдущего пункта, дообучив двумя способами\n",
        "*cointegrated/rubert-tiny2* из huggingface."
      ],
      "metadata": {
        "id": "eUqhI4mV_RTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rubert_tiny_transformer_model = #...\n",
        "rubert_tiny_finetuned_with_freezed_backbone = train_transformer(rubert_tiny_transformer_model, freeze_backbone=True)\n",
        "\n",
        "rubert_tiny_transformer_model = #...\n",
        "rubert_tiny_full_finetuned = train_transformer(rubert_tiny_transformer_model, freeze_backbone=False)"
      ],
      "metadata": {
        "id": "nuxOCBQHAKZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 5 (1 балл)\n",
        "\n",
        "Обучите *tbs17/MathBert* (с замороженным backbone и без заморозки), проанализируйте результаты. Сравните скоры с первым заданием. Получилось лучше или нет? Почему?"
      ],
      "metadata": {
        "id": "zRi7tkoOAjon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE IS HERE (probably, similar on the previous step)"
      ],
      "metadata": {
        "id": "XKtd3YgNA14E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 6 (1 балл)\n",
        "\n",
        "Напишите функцию для отрисовки карт внимания первого слоя для моделей из задания"
      ],
      "metadata": {
        "id": "EuU6Di26017B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_first_layer_attention_maps(attention_head_ids: List, text: str, model: TransformerClassificationModel):\n",
        "    pass"
      ],
      "metadata": {
        "id": "guzGxfcV1Cba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 7 (1 балл)\n",
        "\n",
        "Проведите инференс для всех моделей **ДО ДООБУЧЕНИЯ** на 2-3 текстах из датасета. Посмотрите на головы Attention первого слоя в каждой модели на выбранных текстах (отрисуйте их отдельно).\n",
        "\n",
        "Попробуйте их проинтерпретировать. Какие связи улавливают карты внимания? (если в модели много голов Attention, то проинтерпретируйте наиболее интересные)"
      ],
      "metadata": {
        "id": "Iu0adKw4BLtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE IS HERE"
      ],
      "metadata": {
        "id": "U2gEF3vkB6eR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 8 (1 балл)\n",
        "\n",
        "Сделайте то же самое для дообученных моделей. Изменились ли карты внимания и связи, которые они улавливают? Почему?"
      ],
      "metadata": {
        "id": "pBNVrOpCCLqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE IS HERE"
      ],
      "metadata": {
        "id": "F5229WBICWEr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}